{"componentChunkName":"component---src-templates-blog-post-js","path":"/data-science/facebook-cambridge-analytica/","webpackCompilationHash":"5f9591ebff2f486b77ad","result":{"data":{"site":{"siteMetadata":{"title":"renuevo blog","author":"deokhwa kim","siteUrl":"https://renuevo.github.io","comment":{"disqusShortName":"https-renuevo-github-io","utterances":""},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"80b518ef-bbbd-522b-abee-2bff2bc922e6","excerpt":"해당 포스팅은 이전에 속에 사용된 을 조사한 자료가 있어서 포스팅 하게 되었습니다   이 포스팅은 확실한 명확한 해답이 아니며 여러 의견을 분석한 자료를 토대로 작성되었습니다   사건 요약 2014년 심리학 박사 알렉산더 코겐 교수(Dr. Aleksandr )가 ‘this is your digital life’로 부르는 성격 테스트 서비스를 설계했다   소셜 로그인이 필요했던 앱은 페이스북 정책상 허점을 이용해 사용자 뿐 아니라 가입된 2…","html":"<p>해당 포스팅은 이전에 <code class=\"language-text\">2016년 트럼프 대선 당시 사용된 전략</code>속에 사용된 <code class=\"language-text\">IT기술</code>을 조사한 자료가 있어서 포스팅 하게 되었습니다  </p>\n<br/>\n<p><strong><em>이 포스팅은 확실한 명확한 해답이 아니며 여러 의견을 분석한 자료를 토대로 작성되었습니다</em></strong>  </p>\n<h2 id=\"사건-요약\"><a href=\"#%EC%82%AC%EA%B1%B4-%EC%9A%94%EC%95%BD\" aria-label=\"사건 요약 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>사건 요약</h2>\n<ol>\n<li>2014년 심리학 박사 알렉산더 코겐 교수(Dr. Aleksandr <code class=\"language-text\">Kogan</code>)가 ‘this is your digital life’로 부르는 성격 테스트 서비스를 설계했다  </li>\n<li>소셜 로그인이 필요했던 앱은 페이스북 정책상 허점을 이용해 사용자 뿐 아니라 가입된 27만 명의 페이스북 친구 네트워크 정보까지 알 수 있었고 이런 식으로 5천만 명의 데이터가 수집됐다  </li>\n<li>이를 인지한 페이스북은 데이터 삭제를 요구했으나 와이어드가 확인한 결과 2017년에도 여전히 접속할 수 있다  </li>\n<li>이 데이터는 심리학적 프로파일을 만드는 데 사용할 수 있으며 코겐이 소속된 회사 CA가 이를 바탕으로 2016년 대선 트럼프 캠프에 리포트를 제공했다는 의혹이 언론에서 불거졌다  </li>\n</ol>\n<h2 id=\"요약\"><a href=\"#%EC%9A%94%EC%95%BD\" aria-label=\"요약 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>요약</h2>\n<ol>\n<li>페이스북 소셜 로그인으로 사용자의 정보접근권한을 부여 받음  </li>\n<li>권한을 토대로 사용자 및 친구들의 같이 좋아요한 친구등의 데이터까지 수집  </li>\n<li>좋아요 페이지 및 특정 거주지역, 종교, 나이등을 토대로 성격 프로파일링 데이터로 사용됨  </li>\n</ol>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50.71151358344114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAAB1UlEQVQoz41S227bMAz11w3Yn27v64DtbRhSDHGc2kHQeG2arVl8i6+yfJHsSGeU3aLb0IcRICQdkYfUEa2yzFFVJczKWIWiLMAq4yWKIkOantE0HP9rVpokiOIYURQhjmJw3oCXJcIgQGLuCG+aBoMUSMKQzvGEa61RU3GzP59TxLHJ5bAOhx9wXQ+rlYPtdou2bXEissXiGuv1Dd25CIlISomlbU+Y4zjI8xwB4ba9mvJNriG3fN+fkjzPw933u6lyShX393vsdjuY++PxCCkkxWwmPMsy9H0/EayI0DTj73ySroLFGENCzyqooiEzZtbxcoEcLxjIFe21UlDkzzHGurYjjVMEwYn27azhX4o+BY9KY3GqcSw7jET4r6lhgH7lQ7RWsBRpk364ggjCCbw9c5xYjyLJEOQct6VEuXbBSTdDwm88iHCOlfRE04NICUucuUPVC6RXH9E+PEzAz7Sm0akh7SWqKMFjr5F/+Yrs02eMhpDIByJiSxvum7foDo8Y2BZ9eP3y5LGuMQoxAW3TYfMrpxmssTnRPAqiET11w6Donn1bQtDoCDNW795jqDlpK6HkPKvWnyIbExeN+7xFMyrsaeVynPV58oE+T9EPv6a9sd9XF/SLpB6jxAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cambridge.png\"\n        title=\"cambridge.png\"\n        src=\"/static/71868dfd05a5db63e6f2a90c055eed43/36727/cambridge.png\"\n        srcset=\"/static/71868dfd05a5db63e6f2a90c055eed43/acf4b/cambridge.png 173w,\n/static/71868dfd05a5db63e6f2a90c055eed43/fc834/cambridge.png 345w,\n/static/71868dfd05a5db63e6f2a90c055eed43/36727/cambridge.png 690w,\n/static/71868dfd05a5db63e6f2a90c055eed43/6ca41/cambridge.png 773w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span>\n<span class='img_caption'>source : <a href=\"http://blog.naver.com/PostView.nhn?blogId=kpfjra_&#x26;logNo=221260402045&#x26;categoryNo=13&#x26;parentCategoryNo=0\">신문과 방송 블로그</a></span></p>\n<h2 id=\"프로파일링-데이터를-사용할때-사용된-기술들\"><a href=\"#%ED%94%84%EB%A1%9C%ED%8C%8C%EC%9D%BC%EB%A7%81-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%A0%EB%95%8C-%EC%82%AC%EC%9A%A9%EB%90%9C-%EA%B8%B0%EC%88%A0%EB%93%A4\" aria-label=\"프로파일링 데이터를 사용할때 사용된 기술들 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>프로파일링 데이터를 사용할때 사용된 기술들</h2>\n<p><strong>유저 프로파일링</strong>에 대해서는 <code class=\"language-text\">2가지</code>의 기술을 접목해서 사용하였습니다  </p>\n<br/>\n<p><strong>첫 번째</strong>는 <a href=\"https://ko.wikipedia.org/wiki/5%EA%B0%80%EC%A7%80_%EC%84%B1%EA%B2%A9_%ED%8A%B9%EC%84%B1_%EC%9A%94%EC%86%8C\">BIG FIVE</a>라는 성격유형 검사입니다<br>\n케임브리지 애널리티카는 사용자의 <code class=\"language-text\">BIG FIVE</code>심리검사와 <code class=\"language-text\">거주지역, 종교, 나이</code> 통해 사용자를 샘플링 하였고 <code class=\"language-text\">좋아요</code>를 표시한 포스팅과 관계분석를 분석하여<br>\n32만여명의 데이터를 통해 5000만명의 친구들까지 분석할 수 있는 데이터 셋을 생성할 수 있었습니다     </p>\n<br/>\n<p><strong>두 번째</strong>는 <a href=\"https://en.wikipedia.org/wiki/Latent_semantic_analysis\">LSA</a>라는 알고리즘입니다  </p>\n<p><strong>1. co-occurrence matrix <a href=\"https://en.wikipedia.org/wiki/Co-occurrence_matrix\">(동시발생 행렬)</a></strong><br>\n앞서 말씀드린 데이터셋 구축에서 사용된 <code class=\"language-text\">kogan</code>의 자체 알고리즘을 전문가들은<br>\n<code class=\"language-text\">multi step co-occurrence matrix</code>를 활용한 알고리즘으로 예측 하고 있습니다<br>\n<strong>동시발생 행렬(co-occurrence matrix)이란</strong> 매트릭스 값은 동시 발생하는 부분만을 의미론적으로 같은 패턴을 가지는 그룹을 만들 수 있다는 것으로<br>\n이 과정을 multi-step으로 진행하여 내부 값을 정규화하여 데이터셋을 생성한 것으로 예상 됩니다  </p>\n<p><strong>2. SVD <a href=\"https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%9D%B4%EA%B0%92_%EB%B6%84%ED%95%B4\">(차원축소)</a></strong><br>\nSVD는 차원축소 개념으로 유사한 그룹을 생성될 때 쓰입니다\nNetflix에서 추천 서비스에 사용한것으로 유명하며 Cambridge Analytica도 SVD를 사용하여 차원축소하여 프로파일링 했을 확률이 높습니다<br>\n실제 모델 구축자인 kogan과 chancellor은 온전한 SVD를 사용하지 못했다는 말이 있으며<br>\n사용자 간의 좋아요 항목 차로 인해 SVD만으로는 해결하지 못해 자신들만의 자체 알고리즘으로  <code class=\"language-text\">multi step co-occurrence matrix</code>를 사용한 것으로 보입니다  </p>\n<h2 id=\"lsa-알고리즘-이란\"><a href=\"#lsa-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%9D%B4%EB%9E%80\" aria-label=\"lsa 알고리즘 이란 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LSA 알고리즘 이란?</h2>\n<p><strong><em>(Latent Semantic Analysis : 잠재적의미 분석)</em></strong><br>\n<strong>LSA 알고리즘</strong>은 <code class=\"language-text\">co-occurrence + SVD</code>의 조합이라고 할 수 있습니다  </p>\n<p>즉 <code class=\"language-text\">차원축소</code>와 <code class=\"language-text\">동시발생빈도</code>를 통해 각 Item들의 유사도를 분석하는 알고리즘 입니다<br>\nLSA는 기본적으로 DTM이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다는 아이디어를 갖고 있습니다  </p>\n<hr>\n<h2 id=\"train-data-set\"><a href=\"#train-data-set\" aria-label=\"train data set permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Train Data Set</h2>\n<p>일단 처음으로 <code class=\"language-text\">Training Data</code>를 준비합니다<br>\n이 예제에서는 Rand 함수를 써서 과일 Item을 램덤적으로 생성하게 만들었습니다  </p>\n<p><strong>LsaModelService.java</strong>  </p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\">    <span class=\"token comment\">//Train Data Set Create</span>\n    <span class=\"token class-name\">List</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">Set</span><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">></span><span class=\"token punctuation\">></span></span> trainDataList <span class=\"token operator\">=</span> dataRepository<span class=\"token punctuation\">.</span><span class=\"token function\">createTrainDataSet</span><span class=\"token punctuation\">(</span><span class=\"token number\">45</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.4078624078624%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA1ElEQVQoz6WRaw6EIBCDvY6Ab0QQZb3/pbqURN1s1M3qj8bROF/aTjZNM5xz8N6h1z2qqoIsSwgqzqooUMaZ3/ks4rsQAlLKQ2XjOGIwBsMwoGnq9LPIc0gucT4QF8+gWQgvLMuCEAK6rksuqLR04uLSIeOavoeJLgms63oHXixeR45xtdYbTCl1H8io8zyDYK27VP6v4i+B3ns462CtTS4JuwPagHTHyIzLqNSnu3+dZmtcHqRt29Th3bj7leOFCWN/3w5vdmiTS/ZI6GPgGvVpf9QbBp5vJwescuoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"LSA Train Data Set\"\n        title=\"LSA Train Data Set\"\n        src=\"/static/6aa42185c63f126c3f1478c110a28df0/36727/LSA-Train-Data.png\"\n        srcset=\"/static/6aa42185c63f126c3f1478c110a28df0/acf4b/LSA-Train-Data.png 173w,\n/static/6aa42185c63f126c3f1478c110a28df0/fc834/LSA-Train-Data.png 345w,\n/static/6aa42185c63f126c3f1478c110a28df0/36727/LSA-Train-Data.png 690w,\n/static/6aa42185c63f126c3f1478c110a28df0/17fa4/LSA-Train-Data.png 1035w,\n/static/6aa42185c63f126c3f1478c110a28df0/a5044/LSA-Train-Data.png 1380w,\n/static/6aa42185c63f126c3f1478c110a28df0/c6a5f/LSA-Train-Data.png 1628w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span>\n<span class='img_caption'>LSA Sample Data</span></p>\n<br/>\n<h2 id=\"train-data-matrix\"><a href=\"#train-data-matrix\" aria-label=\"train data matrix permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Train Data matrix</h2>\n<p>다음으로 Data Set을 기반으로 Matrix를 생성합니다<br>\nMatrix는 Row를 데이터 쌍의 개수로 생성하고 N개의 Item을 Column으로 기준을 삼아서 생성합니다  </p>\n<p><strong>LsaModelService.java</strong>  </p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\">    <span class=\"token comment\">//Train Matrix Data Set Create</span>\n    <span class=\"token class-name\">Matrix</span> matrix <span class=\"token operator\">=</span> lsaModelComponent<span class=\"token punctuation\">.</span><span class=\"token function\">createMatrix</span><span class=\"token punctuation\">(</span>trainDataList<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.41373801916933%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAlklEQVQoz52R6xKFIAiEfSJZ8fL+b0ZC0aiVc+b8oM9qWdgKrTVhZsm9Ui/kLEhJcqc+ByAgEuql5zemrleqPuglxmgvnUTRBLQxOrVp6lXjUGudpigBJ6z8PGreyJwllFJud5vuvMy81ohjj99b5K3hYPxlONIMNfI6DbRExhxZG08tP3/KY8Nhm18iG7GLjD+/4bXhAV1E+ZNA3ZKWAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"LSA Data Matrix\"\n        title=\"LSA Data Matrix\"\n        src=\"/static/2ae6a17f7099527d2b3e290c92b8d0fb/36727/Data-Matrix.png\"\n        srcset=\"/static/2ae6a17f7099527d2b3e290c92b8d0fb/acf4b/Data-Matrix.png 173w,\n/static/2ae6a17f7099527d2b3e290c92b8d0fb/fc834/Data-Matrix.png 345w,\n/static/2ae6a17f7099527d2b3e290c92b8d0fb/36727/Data-Matrix.png 690w,\n/static/2ae6a17f7099527d2b3e290c92b8d0fb/17fa4/Data-Matrix.png 1035w,\n/static/2ae6a17f7099527d2b3e290c92b8d0fb/a5044/Data-Matrix.png 1380w,\n/static/2ae6a17f7099527d2b3e290c92b8d0fb/002c2/Data-Matrix.png 2504w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span><br>\n<span class='img_caption'>Matrix Sample</span>\n<span class='img_caption'>참고로 해당 이미지는 옆이 짤렸습니다</span></p>\n<br/>\n<h2 id=\"svd-and-reduction\"><a href=\"#svd-and-reduction\" aria-label=\"svd and reduction permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SVD And Reduction</h2>\n<p>SVD(특이값 분해)로 한개의 Matrix를 3개의 Matrix로 분리합니다<br>\nSVD에 대해 자세한 방법을 알고 싶으시면 👉 <a href=\"https://www.youtube.com/watch?v=cq5qlYtnLoY&#x26;feature=emb_logo\">공돌이의 수학정리노트</a></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.048923679060664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABcRAAAXEQHKJvM/AAABj0lEQVQY02MI6j3E6tWwgdWnaQsrkM3iXrWCAQScCmczZ275waFg7iNlk9HPX7z/PwuDUQbnwonN4g5OrsrF1U2iSZn5HEW3/rPo+WULKVkHiZWe+M/OEDnj4pXo2dcuRc++egvI3ho25QwbyMComZeNgfh55MxLz6NnXfkWOuVsR9HiCzXLTz7/8f///0dfv//69uTtt3CfiedXxMy6/BGo7knUrMuPGOIW3PkfOf3C/9h5t/4DDX3o07SJHWSgX+t2p7gFd/+HTDj2P2npo//OHcfmv3r5YvLmm7//rzpy+y/Q0P+3Hr3M8O4/eyJh4Z3/4VNO/weZxQB03d+Q/qO/QQLRc67dcMidxgE0j929cpl7zLyb/4N7D/1JXHzvv0PLoflPHz+YCjJo8tbLPw/d//n/yZMnWZ69p4/Gzb3+P3Ti8T8xc6//A3ntP5DxN27h3f9RMy/diph+AexloEWmQG98A1ryMX7BLaALj0989/5j638I+Djv+Jv/pavvxoZPv7gnHqgX6LufQP2/AScG7P3RhyhtAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"SVD Matrix\"\n        title=\"SVD Matrix\"\n        src=\"/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/36727/svd-image.png\"\n        srcset=\"/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/acf4b/svd-image.png 173w,\n/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/fc834/svd-image.png 345w,\n/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/36727/svd-image.png 690w,\n/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/17fa4/svd-image.png 1035w,\n/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/a5044/svd-image.png 1380w,\n/static/e9100bb3e6ec5ce2efa2b4bb7a9a553c/59300/svd-image.png 1533w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span>  </p>\n<p>Matrix 45 x 41개를 기준으로 SVD 알고리즘을 통해서 각각의 USV의 Matrix를 얻을 수 있습니다  </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">A = USV\nU : Row차원 공간에 Column만개의 단어에 대응되는 점으로 표현  \nS : Column차원 공간에 Row만개의 문서에 대응되는 점으로 표현  \nV : 차원의 중요도를 나타내는 대각행렬  </code></pre></div>\n<br/>\n<p>이후 S(대각 행렬)과 U와 V 모두 각가의 대응되는 행과 열을 제거하여 차원을 축소해 줍니다  </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 26.123778501628664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABcRAAAXEQHKJvM/AAABJ0lEQVQY02NgwAJi591C4TvkTWeCMhmBmJUBH4iccXF+1Kwrc4F4ceSMC+0hE4+zQMXVwqac3hzcd0QjLMgHZBBDYPOGwgU7zh3/9///2h+//+68cveps9+kCxOCe/Zf8G3ZejxmzvV9DAlLHv6PW3Dnf9Lyp/+Bhj7za93BBtLs37bTKXLmpf/hU8+awSzfcfTi8s1Xv/z/9R8Cbj14lmLffqIgaurphcF9h6dFz7k2kyF6zvXfQb0Hf4ZOOvE/Zu6Nq5ZJ7exAveyO+TM9Azp2/wmbfMoEZiDQjH6QQX///vsOoj99/xOKxcsXQC77Cwy3/5HTL9wM7j/KBg1HU6Bln8KnnTOGqf3y/Xcn1HGvgd7+//bTj2CQ+OIjD9mBPmOJmH6BBQBlEKvJVCWZmgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"SVD Matrix\"\n        title=\"SVD Matrix\"\n        src=\"/static/3dab53b65b4b788b1095b81870b1b999/36727/svd-reduction-image.png\"\n        srcset=\"/static/3dab53b65b4b788b1095b81870b1b999/acf4b/svd-reduction-image.png 173w,\n/static/3dab53b65b4b788b1095b81870b1b999/fc834/svd-reduction-image.png 345w,\n/static/3dab53b65b4b788b1095b81870b1b999/36727/svd-reduction-image.png 690w,\n/static/3dab53b65b4b788b1095b81870b1b999/17fa4/svd-reduction-image.png 1035w,\n/static/3dab53b65b4b788b1095b81870b1b999/a5044/svd-reduction-image.png 1380w,\n/static/3dab53b65b4b788b1095b81870b1b999/146f2/svd-reduction-image.png 1535w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span>   </p>\n<p>이걸로 차원까지 축소된 SVD 값을 얻게 되었습니다<br>\n이 Matrix들을 통해서 다음과 같은 조합으로 각 Item들 간의 특이값을 통한 연관성을 알 수 있습니다  </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1. ROW - 차원간의 유사도 U X S 행렬의 row 간의 유사도로 계산한다  \n2. ROW와 Column - ROW S X V 행렬의 column 간의 유사도로 계산한다  \n3. Column - USV의 각 요소가 row와 column간의 유사도이다  </code></pre></div>\n<br/>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 11.73848439821694%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAaElEQVQI103NSw7DIAwE0FwH0xok/jEm9z/V1ERC6mI08iyeLxGB6sItGaNVfD+MlBK4VrjeQXPCtfZu3e7dMUaEEMDM8N6DiN7euTa41gOZBfcBs4GGuDFAqgY35FLssaJYH+TkH/0BE6E/YdisaTQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"SVD Matrix\"\n        title=\"SVD Matrix\"\n        src=\"/static/c36422b156b3f50819e9fb99b05e5e46/36727/SVD.png\"\n        srcset=\"/static/c36422b156b3f50819e9fb99b05e5e46/acf4b/SVD.png 173w,\n/static/c36422b156b3f50819e9fb99b05e5e46/fc834/SVD.png 345w,\n/static/c36422b156b3f50819e9fb99b05e5e46/36727/SVD.png 690w,\n/static/c36422b156b3f50819e9fb99b05e5e46/17fa4/SVD.png 1035w,\n/static/c36422b156b3f50819e9fb99b05e5e46/50151/SVD.png 1346w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span><br>\n<span class='img_caption'>SVD Matrix</span></p>\n<br/>\n<h2 id=\"lsa-sample\"><a href=\"#lsa-sample\" aria-label=\"lsa sample permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LSA Sample</h2>\n<p>이후 알고 싶은 각 Matrix를 조합하여 <code class=\"language-text\">Cosine 유사도</code>를 구하면 각각의 데이터의 유사도를 찾아 낼 수 있습니다  </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 63.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABMklEQVQ4y42SW3KDMAxFWU6NocME24BfPLL/Nd1KDiRuixM+NOLDHB9Zt7LWwjkH6xRU36NtW9zGEcJoSO7DAG0MvPcIIaDrOtR1DSnlaVV80PsA5xWM0vgmYE+XCIJJ7tOEgWqZZ2zbhqZpnsAzcMWG1pKh7clQJeDD0PwynAnIl7+zexqGEOGDLhrqweC+3RFjhBDiPfCKodIay7KAz34EOu/SG3p6Q70b3siKQZI71QHkpXwc2dKGnfNUBDwMcyBZHm/II5eW8TLcgdb1RaCh73VdrxkyMMUmM0xLYaB9AAcqtmNoHpviUv6PvC+F+z4yA+N8ceQj2DqPzWFIY/PIHGw+m/9cDrZ7xaYtBZsNY0ixyaPzF1r5cBJsuuCLxpXUBV04kiVvmZcy0TdLlAx/AETVnDxxBbljAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Column Similarity\"\n        title=\"Column Similarity\"\n        src=\"/static/fbff878b5f814441349883ce169e3e9d/36727/LSA-Column-Similarity.png\"\n        srcset=\"/static/fbff878b5f814441349883ce169e3e9d/acf4b/LSA-Column-Similarity.png 173w,\n/static/fbff878b5f814441349883ce169e3e9d/fc834/LSA-Column-Similarity.png 345w,\n/static/fbff878b5f814441349883ce169e3e9d/36727/LSA-Column-Similarity.png 690w,\n/static/fbff878b5f814441349883ce169e3e9d/17fa4/LSA-Column-Similarity.png 1035w,\n/static/fbff878b5f814441349883ce169e3e9d/a5044/LSA-Column-Similarity.png 1380w,\n/static/fbff878b5f814441349883ce169e3e9d/f688a/LSA-Column-Similarity.png 1575w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        loading=\"lazy\"\n      />\n    </span><br>\n<span class='img_caption'>Item Similarity Result</span>  </p>\n<p>모든 소스 코드 👉 <a href=\"https://github.com/renuevo/data-modeling-algorithm\">Renuevo github</a></p>\n<h2 id=\"참고-사이트\"><a href=\"#%EC%B0%B8%EA%B3%A0-%EC%82%AC%EC%9D%B4%ED%8A%B8\" aria-label=\"참고 사이트 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>참고 사이트</h2>\n<p><a href=\"https://sragent.tistory.com/entry/Latent-Semantic-AnalysisLSA\">내 마음을 알아주는 검색 LSA</a><br>\n<a href=\"https://wikidocs.net/24949\">딥 러닝을 이용한 자연어 처리 입문</a><br>\n<a href=\"https://technowiki.wordpress.com/2011/08/27/latent-semantic-analysis-lsa-tutorial/\">Latent Semantic Analysis (LSA) Tutorial</a><br>\n<a href=\"https://darkpgmr.tistory.com/106\">SVD 특이값 분해 (다크 프로그래머 블로그)</a>  </p>","frontmatter":{"title":"[DataScience] 페이스북을 활용한 트럼프의 대선 전략과 LSA 알고리즘","date":"December 10, 2019"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/data-science/facebook-cambridge-analytica/","previous":{"fields":{"slug":"/spring/resttemplate-thread-safe/"},"frontmatter":{"title":"[Spring] RestTemplate Thread Safe?","category":"Spring"}},"next":{"fields":{"slug":"/spring/scope/spring-scope/"},"frontmatter":{"title":"[Spring] Spring의 Scope와 ProxyMode 알아보기","category":"Spring"}}}}}